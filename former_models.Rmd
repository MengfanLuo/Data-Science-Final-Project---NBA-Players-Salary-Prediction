---
title: "p8106 - Final Project - NBA Players Salary Prediction"
author: "Mingkuan Xu, Mengfan Luo, Yiqun Jin"
date: "5/6/2022"
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,dpi=300)
library(tidyverse)
library(caret)
library(patchwork)
library(mgcv)
library(earth)
library(corrplot)
library(vip)
library(ggpubr)
```

# Introduction

Describe your data set. Provide proper motivation for your work.

What questions are you trying to answer?
How did you prepare and clean the data?

## Data Preprocessing

## Part 0 - Data Preprocessing

```{r joining datasets}
df_salary = read_csv("NBA_season2122_player_salary.csv") %>%
  janitor::clean_names() %>%
  select(Player=x2,Team=x3,Salary=salary_4) %>%
  na.omit()

df_salary = df_salary[-1,]

df_stats = read_csv("NBA_season2122_player_stats.csv") %>%
  rename(Team=Tm) %>%
  select(-Rk)

df_players = inner_join(x=df_salary,y=df_stats,by=c("Player","Team")) %>% 
  janitor::clean_names() %>% 
  distinct()

df_players = df_players %>% 
  arrange(player,desc(g)) %>% 
  distinct(player,.keep_all = TRUE)

# Removed variables with missing data and resulted from division of other variables
df_players = df_players %>% 
  select(-x3p_percent, -ft_percent, -fg_percent,-x2p_percent,-e_fg_percent)

# The final generated dataset for use: df_player.
```


```{r data cleaning}
# Convert salary from characters to numbers.
# Convert categorical variables to factors

df_players = df_players %>% 
  separate(salary,into = c("symbol", "salary"),1) %>% 
  select(-symbol)%>% 
  mutate(salary = as.numeric(salary)/1000000,
         team = factor(team),
         pos = factor(pos)) %>% 
  relocate(salary, .after = last_col())

colnames(df_players) = c("player", "team", "position", "age", "game","game_starting" ,"minute","field_goal", "fg_attempt", "x3p", "x3p_attempt" ,"x2p", "x2p_attempt",   "free_throw",   "ft_attempt", "offensive_rb", "defenssive_rb",  "total_rb" ,   "assistance" ,   "steal" , "block",    "turnover",  "personal_foul", "point", "salary")

df_players = df_players %>% 
  distinct(player,.keep_all = TRUE) %>%
  mutate(player = gsub("\\\\.*","",player)) %>%
  `row.names<-`(., NULL) %>% 
  column_to_rownames('player')
```

## Part 1 - Exploratory Analysis 

Since `minute` stands for minutes played per game, we will divided variables stands for counts by `minute` to get a rate. These variables includes `field_goal`, `fg_attempt`    `x3p`, `x3p_attempt`, `x2p`, `x2p_attempt`,   `free_throw`,  `ft_attempt`, `offensive_rb`  `defenssive_rb`, `total_rb`, `assistance`,`steal`, `block`, `turnover`, `personal_foul` and `point`.

```{r}
df_players = df_players %>% 
  mutate(field_goal = field_goal/minute,
         fg_attempt = fg_attempt/minute,
         x3p = x3p/minute,
         x3p_attempt = x3p_attempt/minute,
         x2p = x2p/minute,
         x2p_attempt = x2p_attempt/minute,
         free_throw = free_throw/minute,
         ft_attempt = ft_attempt/minute,
         offensive_rb = offensive_rb/minute,
         defenssive_rb = defenssive_rb/minute,
         total_rb = total_rb/minute,
         assistance = assistance/minute,
         steal = steal/minute,
         block = block/minute,
         turnover = turnover/minute,
         personal_foul = personal_foul/minute,
         point = point/minute) 
```



### Univariate Analysis

Distributions of the two categorical variables, `team` and `position`.

```{r}
par(mfrow=c(1,2))
plot_team = ggplot(df_players) + geom_bar(aes(team)) + 
  scale_x_discrete(guide = guide_axis(check.overlap = TRUE))+ theme_bw()
plot_team
plot_position = ggplot(df_players) + geom_bar(aes(position)) + theme_bw()
plot_position
```

Distributions of other numeric variables. 

```{r dpi=300}
plot_data_column = function (data, column) {
    ggplot(data, aes_string(x = column)) +
        geom_histogram(bins=15) +
        xlab(column) + theme_bw(base_size = 10)
}

histograms <- lapply(colnames(df_players)[4:24], 
                       plot_data_column, data = df_players)

figure_a = ggarrange(plotlist = histograms[1:9], 
          ncol = 3, nrow = 3)

annotate_figure(figure_a, 
                top = text_grob("Histograms of Predictive Variables (Group A)", 
                                face = "bold", size = 15))


figure_b = ggarrange(plotlist = histograms[10:18], 
          ncol = 3, nrow = 3)
annotate_figure(figure_b, 
                top = text_grob("Histograms of Predictive Variables (Group B)", 
                                face = "bold", size = 15))

figure_c = ggarrange(plotlist = histograms[19:21],
          ncol = 3, nrow = 3)
annotate_figure(figure_c, 
                top = text_grob("Histograms of Predictive Variables (Group C)", 
                                face = "bold", size = 15))
```


### Correlation Analysis

```{r}

df_corr_1 = df_players %>% 
  select(-team,-position)

corrplot(cor(df_corr_1),type = "lower")

```


### Analyzing trends in data

From numeric variables, we found that `stl`,`x3p`, `age`,`gs` seem to have some non-linear trends.

```{r, fig.height=4}
theme1 <- trellis.par.get()
theme1$plot.symbol$col <- rgb(0, 0, 0, 1) 
theme1$plot.symbol$pch <- 16
theme1$plot.line$col <- rgb(1, .1, .1, 1) 
theme1$plot.line$lwd <- 2 
theme1$strip.background$col <- rgb(.0, .2, .6, .2) 
trellis.par.set(theme1)

df_features = df_players[4:13]
featurePlot(x = df_features, 
            y = df_players$salary,
            plot = "scatter",
            # span = .5,
            labels = c("Predictors","Player Salary (Millions)"), 
            type = c("p", "smooth"), 
            layout = c(5, 2))

df_features = df_players[14:23]
featurePlot(x = df_features, 
            y = df_players$salary,
            plot = "scatter",
            # span = .5,
            labels = c("Predictors","Player Salary (Millions)"), 
            type = c("p", "smooth"), 
            layout = c(5, 2))
```

From categorical variable `position`, extremely high values in salary show in all positions and some teams.

```{r fig.height=4}
df_players %>% 
  mutate(
    pos = fct_reorder(position,salary)
  ) %>% 
  ggplot(aes(x = position, y = salary, group = pos, fill = pos))+
  geom_boxplot() + theme_bw()

```

# Models

## Data Partition

After getting an overview of data from exploratory analysis, we splitted the dataset into training (75%) and testing (20%). We would use 10 fold repeated cross validation to compare each model using training data and then select a best model to predict on testing data. Based on the exploratory analysis, we would build 7 models in three category: 
1. Linear Regression: (1) simple Linear Regression Model, (2) Elastic-net Model, (3) Principal Component Regression Model (PCR)
2. Generalized Linear Regression: (4) Generalized Addictive Model (GAM), (5) Multivariate Adaptive Regression Splines Model (MARS)
3. Other Non-linear Models: (6) Random Forest, (7) Blackbox Model (neural network)

```{r}
# Data partition
set.seed(8106)

indexTrain <- createDataPartition(y = df_players$salary, p = 0.75, list = FALSE, times = 1)
df_train <- df_players[indexTrain, ]
df_test <- df_players[-indexTrain, ]
df_train_2 = model.matrix(salary ~ ., df_train)[ ,-1]
df_test_2 = model.matrix(salary ~ ., df_test)[ ,-1]
x = df_train_2
y = df_train %>% pull(salary)

ctrl1 <- trainControl(method = "repeatedcv", number = 10, repeats = 5)
```

## Part 1 Linear regression

### (a) Standard Least-Squared

There is no tuning parameter for standard least-squared model.

```{r least squared, echo=FALSE,message=FALSE,warning=FALSE}
set.seed(8106)
lm.fit <- train(x, y, method = "lm", trControl = ctrl1)
#summary(lm.fit)
lm.pred <- predict(lm.fit, newdata = df_test_2)
lm.mse = mean((lm.pred - df_test$salary)^2)
lm.mse
```

### (b) Elastic Net 

The elastic-net model has two parameter, which are alpha for the compromise between LASSO and ridge and lambda for the complexity. The elastic-net model reached its best tune at $\alpha = 1$ (i.e. LASSO model) and lambda = 0.27.

```{r elastic net, echo = FALSE, message = FALSE, warning = FALSE}
set.seed(8106)
elnet.fit <- train(x, y, method = "glmnet",
                   tuneGrid = expand.grid(alpha = seq(0, 1, length = 11),
                   lambda = exp(seq(3, -3, length = 100))),
                   trControl = ctrl1)
elnet.fit$bestTune
myCol <- rainbow(25)
myPar <- list(superpose.symbol = list(col = myCol),
              superpose.line = list(col = myCol)) 

plot(elnet.fit, par.settings = myPar)

elnet.pred = predict(elnet.fit, newdata = df_test_2)
elnet.mse = mean((elnet.pred - df_test$salary)^2)
```

###(c) Principle Component Regression

The tuning parameter of PCR is the number of predictors included in the final model. There are 5 components included in the model with minimum RMSE. 

```{r principal component regression, echo = FALSE, message = FALSE, warning = FALSE}
set.seed(8106)
pcr.fit <- train(x, y, method = "pcr", tuneLength = 20, trControl = ctrl1)
pcr.pred = predict(pcr.fit, newdata = df_test_2)
pcr.mse = mean((pcr.pred - df_test$salary)^2)
ggplot(pcr.fit, highlight = TRUE)
```

## Part 2 Generalized Linear Regression

### (a) GAM

There is no tuning parameter for GAM. The GAM model can capture the non-linear trend in the model, but it may have a high variance. `age`, `game_starting`, `assistance`, `personal_foul`, and `point` are statistically significant predictors at 0.0001 significant level.

```{r GAM, echo=FALSE,message=FALSE,warning=FALSE}
set.seed(8106)

gam.fit <- gam(salary~
               s(age)+s(game)+s(game_starting)+s(free_throw)+s(ft_attempt)+s(defenssive_rb)
               +s(assistance)+s(block)+s(personal_foul)+s(point),
               data = df_train)
summary(gam.fit)
gam.pred = predict(gam.fit, newdata = df_test)
gam.mse = mean((gam.pred - df_test$salary)^2)
gam.mse
```


### (b) MARS

The tuning parameter for MARS is `nprune` and `degree`. When attempting to fit the MARS model, we noticed that the RMSE increased drastically when degree is over 3 and nprune is over 8. Therefore, we would choose the range of degrees as 1:3 and range of nprune as 2:8. When number of terms is 6 and product degree is 2, MARS model reached its best tune and RMSE is lowest. The MARS model selected 6 of 69 terms, and 6 of 54 predictors. And the top 3 important predictors are: `age`, `minute`, `game`. MARS model is highly adaptive comparing with previous models and has a higher prediction accuracy.

```{r MARS, echo = FALSE, message = FALSE, warning = FALSE}
set.seed(8106)
mars_grid <- expand.grid(degree = 1:3, 
                         nprune = 2:8)

mars.fit <- train(x, y,
                  method = "earth",
                  tuneGrid = mars_grid,
                  trControl = ctrl1)

mars.fit$bestTune
summary(mars.fit)
ggplot(mars.fit) + theme_bw()

mars.pred = predict(mars.fit, newdata = df_test_2)
mars.mse = mean((df_test$salary - mars.pred)^2)
mars.mse
```

## Model Comparison

The CV RMSE are shown as followed. We can see MARS model has lowest RMSE. 

```{r summary, echo=FALSE,message=FALSE,warning=FALSE}
resamp <- resamples(list(LeastSquare = lm.fit,ElasticNet = elnet.fit,PCR = pcr.fit, MARS = mars.fit))

summary(resamp)$statistics$RMSE %>% knitr::kable(caption = "RMSE of Different Models",digits = 2)

bwplot(resamp, metric = "RMSE")
```

```{r test RMSE, echo=FALSE,message=FALSE,warning=FALSE}
test_RMSE <- data.frame (
  Methods = c("Linear","ElasticNet","PCR","GAM","MARS"),
  Test_MSE = c(lm.mse,elnet.mse,pcr.mse,gam.mse,mars.mse)
) %>%
  mutate(RMSE=round(sqrt(Test_MSE),digit=2)) %>%
  select(-Test_MSE) %>%
  t() %>%
  as.data.frame()

colnames(test_RMSE) <- test_RMSE[1,]
test_RMSE <- test_RMSE[-1, ] 


test_RMSE %>% knitr::kable(caption = "RMSE of Different Models on Test Set")
```

